---
title: "3_stats"
author: "MSCI 599"
output: html_document
---

t-test difference in body mass btwn Gentoo and Adelie, Gentoo and chinstrap, and chinstrap and adelie

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.asp = 0.618) 
```

### Intro to t-tests

t-tests are used to assess the difference between two means. When conducting a t-test, you are testing the null hypothesis (H0) that the means are the same. As a standard practice in classical (frequentist) statistics, if the p-value resulting from your t-test is < 0.05, you reject the null hypothesis in favor of the alternative hypothesis, which states that the means are significantly different. 

There are 3 types of t-test:

-  One-sample t-test
-  Independent sample t-test
-  Paired t-test

We'll use the `tidyverse` and our palmer penguins data to run through an example of each of these types of t-test. We'll also load in the package `rstatix` because it contains pipe-friendly statistics functions that play nicely with the `tidyverse.` Don't forget to install the `rstatix` package if it is your first time using it! I'm also going to use the kable() function in the knitr package to print out some of the results tables neatly for this tutorial. This is just for aesthetics, and is not necessary for any of the plotting or statistical tests in this lesson.

```{r, message=FALSE}
library(tidyverse)
library(palmerpenguins)
library(rstatix)
library(knitr)  # prints pretty tables
```

### One-sample t-test

The one-sample t-test, also known as the single-parameter t test or single-sample t-test, is used to compare the mean of one sample to a known standard (or theoretical / hypothetical) mean. 

Generally, the theoretical mean comes from:

-  a previous experiment. For example, comparing whether the mean weight of mice differs from 200 mg, a value determined in a previous study.
-  or from an experiment where you have control and treatment conditions. If you express your data as “percent of control”, you can test whether the average value of treatment condition differs significantly from 100.

The one-sample t-test assumes the following characteristics about the data:

-  No significant outliers in the data
-  Data should be approximately normally distributed

#### Example: Observed Gentoo body mass vs. literature value

Are the Gentoo penguin body mass observations collected in our palmer penguins dataset significantly different than the mean Gentoo penguin body mass accepted in the literature? We can use the body mass value from the Encyclopedia of Life:

https://eol.org/traitbank

Search for "Gentoo Penguin" in the search bar and you will find that the trait bank lists body mass as 6500g. Let's see what our Gentoo body mass observations look like:

```{r}
# Separate just the Gentoo from all the penguin data
gentoo = penguins %>% 
  filter(species=="Gentoo") 

# Quickly visualize the body mass data
ggplot(data=gentoo) +
  geom_histogram(aes(x=body_mass_g))

# Calculate the mean and standard deviation Gentoo body mass in our data (sometimes base R is more sensible than dplyr)
mean(gentoo$body_mass_g, na.rm=TRUE)
sd(gentoo$body_mass_g, na.rm=TRUE)
```

Before we conduct our one-sample t-test, let's first check the assumptions. Are there any significant outliers in the data? The function identify_outliers() uses boxplot methods to return a data frame of outliers (see `?identify_outliers` for more info)

```{r}
# Test for the presence of outliers in the Gentoo body mass data
gentoo %>%
  identify_outliers(body_mass_g)

# Note: here is a result from a made-up dataset where I added an outlier
# data.frame(dat=c(rnorm(100), 312)) %>% identify_outliers()  
```

The identify_outliers() test returned nothing, so there were no outliers in the Gentoo body_mass_g data. 

The normality assumption can be checked by computing the Shapiro-Wilk test. If the data is normally distributed, the p-value should be greater than 0.05. We can also plot the data in a Quantile-Quantile plot (QQ plot) and see if it mostly falls along teh 1:1 line.

```{r}
# Test if the Gentoo body mass data is normal:
gentoo %>% shapiro_test(body_mass_g)

# Check normality assumption with a qqplot:
ggplot(gentoo) +
  stat_qq(aes(sample=body_mass_g))
```

Great - we accepted the null hypothesis of the Shapiro Wilk test: the body mass data was not significantly different from a normal distribution. We also checked the qqplot and the data fell along the 1:1 line, so it looks nice and normal.

Note that, if our sample size is greater than 50, the normal QQ plot is preferred because at larger sample sizes the Shapiro-Wilk test becomes very sensitive even to a minor deviation from normality.

If the data are not normally distributed, it’s recommended to use a non-parametric test such as the one-sample Wilcoxon signed-rank test. This test is similar to the one-sample t-test, but focuses on the median rather than the mean.

Now let's do our one-sample t-test to see if our body mass data is significantly different from the body mass value of 6500 g published in the literature:

```{r}
t_test_results = gentoo %>% t_test(body_mass_g ~ 1, mu = 5950)
kable(t_test_results)
```
The results of our one-sample t-test show the following components:

-  .y.: the outcome variable used in the test.
-  group1,group2: generally, the compared groups in the pairwise tests. Here, we have null model (one-sample test).
-  statistic: test statistic (t-value) used to compute the p-value.
-  df: degrees of freedom.
-  p: p-value.

The output p-value is much less than 0.05 (it's almost p=0). That means we reject our null hypothesis that our Gentoo body mass observations are similar to the literature value.

To calculate an effect size, called Cohen's d, for the one-sample t-test you need to divide the mean difference by the standard deviation of the difference, as shown below. Note that since mu is a constant: sd(x-mu) = sd(x).

Cohen’s d formula:

d = (mean(x) - mu)/sd(x), where:

-  x is a numeric vector containing the data.
-  mu is the mean against which the mean of x is compared (default value is mu = 0).

```{r}
gentoo %>% cohens_d(body_mass_g ~ 1, mu = 6500)
```

Recall that, t-test conventional effect sizes, proposed by Cohen J. (1998), are: 0.2 (small effect), 0.5 (moderate effect) and 0.8 (large effect) (Cohen 1998). As the effect size, d, is -2.82 you can conclude that there is a large effect, and our sample data is less than the supplied literature value mu (=6500).

Huh. Interesting. Remember earlier we caculated our observed mean Gentoo body mass is 5076 g. Maybe our penguins were hungry. If I had to guess, the Encyclopedia of Life body mass trait is probably for adult Gentoo penguins, and we include juveniles in our observations. Or perhaps the Encylcopedia value is junk. If this were actually my data and I wanted to publish on it, I'd use this as a jumping point to do some more research.

### Independent sample t-test:

Assumptions

-  No significant outliers in the groups
-  the two groups of samples (A and B), being compared, should be normally distributed.
-  If using the Student's t-test, the variances of the two groups should not be significantly different. This assumption is relaxed in the Welch’s t-test.


### Paired sample t-test:
No significant outliers in the differences between groups
the difference of pairs should follow a normal distribution.

### Note on assumptions:

**Assessing normality:** With large enough samples size (n > 30) the violation of the normality assumption should not cause major problems (according to the central limit theorem). This implies that we can ignore the distribution of the data and use parametric tests. However, to be consistent, the Shapiro-Wilk test can be used to ascertain whether data show or not a serious deviation from normality (See Chapter @ref(normality-test-in-r)).

**Assessing equality of variances:** Homogeneity of variances can be checked using the Levene’s test. Note that, by default, the t_test() function does not assume equal variances; instead of the standard Student’s t-test, it uses the Welch t-test by default, which is the considered the safer one. To use Student’s t-test, set var.equal = TRUE. The two methods give very similar results unless both the group sizes and the standard deviations are very different.

In the situations where the assumptions are violated, non-parametric tests, such as Wilcoxon test, are recommended.




### Acknowledgements

Although we used our beloved penguin data, the structure of this lesson was inspired by Data Novia:

https://www.datanovia.com/en/lessons/t-test-in-r/

